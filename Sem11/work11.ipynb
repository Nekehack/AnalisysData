{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c872f81d-2bb2-4fe1-b9ee-93cc1246057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e5d64e03-54c8-4346-a9b2-6553b500c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import PyPDF2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "414f955e-2fb6-4d7a-bbee-3c676e223cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"Искусственный интеллект — это область компьютерных наук, которая занимается созданием систем, способных выполнять задачи, требующие человеческого интеллекта.\",\n",
    "    \"Машинное обучение — это подраздел искусственного интеллекта, который позволяет компьютерам учиться на данных без явного программирования.\",\n",
    "    \"Глубокое обучение использует нейронные сети для обработки больших объемов данных и решения сложных задач.\",\n",
    "    \"Обработка естественного языка — это раздел искусственного интеллекта, который занимается взаимодействием между компьютерами и людьми через текст или речь.\",\n",
    "    \"Семантический поиск — это метод поиска информации, который учитывает смысл запроса и контекст документов.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "144feec9-ac0f-40ab-b2be-4950c6a33899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 1: Инициализация модели\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cf5bc2a2-6eb8-45b0-8c5a-2d3ea1c1b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 2: Преобразование текста в векторы\n",
    "text_embeddings = model.encode(text, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1fb981ce-2682-4276-8507-66da11c9d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 3: Функция для семантического поиска\n",
    "def semantic_search(query, top_k=3):\n",
    "    # Преобразуем запрос в вектор\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    # Вычисляем косинусное сходство между запросом и документами\n",
    "    cos_scores = util.cos_sim(query_embedding, text_embeddings)[0]\n",
    "    \n",
    "    # Сортируем результаты по убыванию сходства\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "    \n",
    "    # Возвращаем подходящие результаты\n",
    "    results = []\n",
    "    for idx, score in zip(top_results.indices, top_results.values):\n",
    "        results.append({\n",
    "            \"text\": text[idx],\n",
    "            \"score\": score.item()\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e9554b0c-ef0e-4fd3-a42e-20e95d845a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты поиска:\n",
      "Сходство: 0.7884\n",
      "Текст: Машинное обучение — это подраздел искусственного интеллекта, который позволяет компьютерам учиться на данных без явного программирования.\n",
      "\n",
      "Сходство: 0.5157\n",
      "Текст: Искусственный интеллект — это область компьютерных наук, которая занимается созданием систем, способных выполнять задачи, требующие человеческого интеллекта.\n",
      "\n",
      "Сходство: 0.5148\n",
      "Текст: Обработка естественного языка — это раздел искусственного интеллекта, который занимается взаимодействием между компьютерами и людьми через текст или речь.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Демонстрация работы\n",
    "query = \"Что такое машинное обучение?\"\n",
    "results = semantic_search(query)\n",
    "\n",
    "print(\"Результаты поиска:\")\n",
    "# Наиболее подходящий результат первый в выводе\n",
    "for result in results:\n",
    "    print(f\"Сходство: {result['score']:.4f}\")\n",
    "    print(f\"Текст: {result['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9021cf80-5b4a-490d-9758-c4c69926e325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x93f for key /F19\n",
      "Multiple definitions in dictionary at byte 0x94c for key /F33\n",
      "Multiple definitions in dictionary at byte 0x12b43 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x13817 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x14570 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x15312 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x16087 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x16df9 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x17bca for key /F19\n",
      "Multiple definitions in dictionary at byte 0x18904 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1960d for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1a365 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1b06e for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1be08 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1cb8a for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1d8a1 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1e586 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1f206 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x1fdc8 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x209af for key /F19\n",
      "Multiple definitions in dictionary at byte 0x21668 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x2236a for key /F19\n",
      "Multiple definitions in dictionary at byte 0x23130 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x23149 for key /F33\n",
      "Multiple definitions in dictionary at byte 0x23d80 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x24994 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x25615 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x26356 for key /F19\n",
      "Multiple definitions in dictionary at byte 0x26f6f for key /F19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество предложений в корпусе: 524\n",
      "Результаты поиска:\n",
      "Сходство: 0.6080\n",
      "Текст: Истоки европейской циви-\n",
      "лизации лежат в античной Греции, создавшей культуру, которая\n",
      "обладает удиви...\n",
      "\n",
      "Сходство: 0.5399\n",
      "Текст: Древние греки\n",
      "явились родоначальниками того рационального гуманизма , кото-\n",
      "рый и сегодня определяет...\n",
      "\n",
      "Сходство: 0.5004\n",
      "Текст: НАУКА И ЕЕ РОЛЬ В СОВРЕМЕННОМ МИРЕ\n",
      "Цивилизация, культура, наука....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Функция для извлечения текста из PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Извлекает текст из PDF-файла.\n",
    "    \n",
    "    :param pdf_path: Путь к PDF-файлу.\n",
    "    :return: Строка с текстом из PDF.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                extracted_page_text = page.extract_text()\n",
    "                if extracted_page_text:  # Проверяем, что текст извлечён\n",
    "                    text += extracted_page_text\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении PDF: {e}\")\n",
    "    return text.strip()  # Убираем лишние пробелы и пустые строки\n",
    "\n",
    "\n",
    "# Функция для разделения текста на предложения\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"\n",
    "    Разделяет текст на предложения с помощью регулярных выражений.\n",
    "    \n",
    "    :param text: Исходный текст.\n",
    "    :return: Список предложений.\n",
    "    \"\"\"\n",
    "    # Регулярное выражение для разделения текста на предложения\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "\n",
    "# Шаг 1: Инициализация модели\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Шаг 2: Загрузка текста из PDF\n",
    "pdf_path = 'natural1.pdf'  # Укажите путь к вашему PDF-файлу\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Если текст успешно извлечён, используем его как корпус\n",
    "if extracted_text:\n",
    "    # Разделяем текст на предложения\n",
    "    text = split_into_sentences(extracted_text)\n",
    "    if not text:\n",
    "        raise ValueError(\"Извлечённый текст пуст или не содержит предложений.\")\n",
    "else:\n",
    "    raise ValueError(\"Не удалось извлечь текст из PDF.\")\n",
    "\n",
    "print(f\"Количество предложений в корпусе: {len(text)}\")\n",
    "\n",
    "# Шаг 3: Преобразование корпуса в векторы\n",
    "text_embeddings = model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "# Шаг 4: Функция для семантического поиска\n",
    "def semantic_search(query, top_k=3):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    # Вычисляем косинусное сходство между запросом и документами\n",
    "    cos_scores = util.cos_sim(query_embedding, text_embeddings)[0]\n",
    "    \n",
    "    # Ограничиваем top_k до количества доступных документов\n",
    "    top_k = min(top_k, len(text))\n",
    "    \n",
    "    # Сортируем результаты по убыванию сходства\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "    \n",
    "    # Возвращаем подходящие результаты\n",
    "    results = []\n",
    "    for idx, score in zip(top_results.indices, top_results.values):\n",
    "        results.append({\n",
    "            \"text\": text[idx],\n",
    "            \"score\": score.item()\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "# Демонстрация работы\n",
    "query = \"Где лежат истоки европейской цивилизации?\"\n",
    "try:\n",
    "    results = semantic_search(query)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Ошибка при выполнении поиска: {e}\")\n",
    "else:\n",
    "    print(\"Результаты поиска:\")\n",
    "    for result in results:\n",
    "        print(f\"Сходство: {result['score']:.4f}\")\n",
    "        print(f\"Текст: {result['text'][:100]}...\\n\")  # Выводим первые 100 символов текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7b14bb86-eb82-4426-ae38-237f9ea23e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты поиска:\n",
      "Сходство: 0.8192\n",
      "Текст: Основная задача изучения естествознания состоит в том, чтобы\n",
      "ясно представить единство природы, ее ц...\n",
      "\n",
      "Сходство: 0.8008\n",
      "Текст: Природа и ее изучение, естествознание....\n",
      "\n",
      "Сходство: 0.7444\n",
      "Текст: Именно в этом смысле естествознание\n",
      "рассматривается как единая система наук о природе, занимающая-\n",
      "с...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вопрос из середины пдф файла\n",
    "query = \"В чём состоит основная задача изучения естествознания?\"\n",
    "try:\n",
    "    results = semantic_search(query)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Ошибка при выполнении поиска: {e}\")\n",
    "else:\n",
    "    print(\"Результаты поиска:\")\n",
    "    for result in results:\n",
    "        print(f\"Сходство: {result['score']:.4f}\")\n",
    "        print(f\"Текст: {result['text'][:100]}...\\n\")  # Выводим первые 100 символов текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9c0b27fa-f899-4ca5-a10b-157f3032b4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты поиска:\n",
      "Сходство: 0.7796\n",
      "Текст: Но наука и не всесильна....\n",
      "\n",
      "Сходство: 0.7768\n",
      "Текст: Одной науки для этого\n",
      "мало, но, чтобы достичь желаемого, вовсе не надо отворачиваться\n",
      "от науки....\n",
      "\n",
      "Сходство: 0.7548\n",
      "Текст: •Возможности науки\n",
      "Сегодня ученые вовсе не считают, что они постигли все тайны\n",
      "мироздания....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вопрос из конца пдф документа\n",
    "query = \"Возможности науки?\"\n",
    "try:\n",
    "    results = semantic_search(query)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Ошибка при выполнении поиска: {e}\")\n",
    "else:\n",
    "    print(\"Результаты поиска:\")\n",
    "    for result in results:\n",
    "        print(f\"Сходство: {result['score']:.4f}\")\n",
    "        print(f\"Текст: {result['text'][:100]}...\\n\")  # Выводим первые 100 символов текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132eb55b-9391-42e3-bc8d-402d68984721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
